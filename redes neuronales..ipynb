{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d325c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageEnhance\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12312515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo inicial: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "Imágenes movidas (undersample): {'Lung_Opacity': 2012, 'Normal': 6192}\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = Path(\"COVID-19_Radiography_Dataset/\")\n",
    "BACKUP_PATH = DATASET_PATH.parent / (DATASET_PATH.name + \"_backup\")\n",
    "TARGET = 4000  # número objetivo por clase (entre 1345 y 10194)\n",
    "\n",
    "# =============================\n",
    "# 1. Conteo inicial\n",
    "# =============================\n",
    "classes = [d for d in DATASET_PATH.iterdir() if d.is_dir()]\n",
    "class_counts = {c.name: len(list(c.glob(\"*\"))) for c in classes}\n",
    "print(\"Conteo inicial:\", class_counts)\n",
    "\n",
    "BACKUP_PATH.mkdir(parents=True, exist_ok=True)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# =============================\n",
    "# 2. Undersampling (para clases con > TARGET)\n",
    "# =============================\n",
    "def undersample_class(class_folder: Path, target: int, backup_root: Path):\n",
    "    files = list(class_folder.glob(\"*\"))\n",
    "    n = len(files)\n",
    "    if n <= target:\n",
    "        return 0\n",
    "    keep = set(random.sample(files, target))\n",
    "    moved = 0\n",
    "    backup_cls = backup_root / class_folder.name\n",
    "    backup_cls.mkdir(parents=True, exist_ok=True)\n",
    "    for f in files:\n",
    "        if f not in keep:\n",
    "            shutil.move(str(f), str(backup_cls / f.name))\n",
    "            moved += 1\n",
    "    return moved\n",
    "\n",
    "moved_summary = {}\n",
    "for cls in classes:\n",
    "    cnt = len(list(cls.glob(\"*\")))\n",
    "    if cnt > TARGET:\n",
    "        moved_summary[cls.name] = undersample_class(cls, TARGET, BACKUP_PATH)\n",
    "print(\"Imágenes movidas (undersample):\", moved_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0585e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aug COVID: 100%|██████████| 384/384 [00:07<00:00, 54.86it/s]\n",
      "Aug Viral Pneumonia: 100%|██████████| 2655/2655 [00:31<00:00, 85.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes creadas (augmentation): {'COVID': 384, 'Viral Pneumonia': 2655}\n",
      "Conteo final por clase: {'COVID': 4000, 'Lung_Opacity': 4000, 'Normal': 4000, 'Viral Pneumonia': 4000}\n"
     ]
    }
   ],
   "source": [
    "# Funciones de augmentación\n",
    "def add_gaussian_noise(pil_img, sigma=8):\n",
    "    arr = np.array(pil_img).astype(np.float32)\n",
    "    noise = np.random.normal(0, sigma, arr.shape)\n",
    "    noisy = np.clip(arr + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy)\n",
    "\n",
    "\n",
    "def random_affine(pil_img, max_translate=5, max_shear=5):\n",
    "    w, h = pil_img.size\n",
    "    trans_x = random.uniform(-max_translate, max_translate)\n",
    "    trans_y = random.uniform(-max_translate, max_translate)\n",
    "    shear = random.uniform(-max_shear, max_shear)\n",
    "    matrix = (1, np.tan(np.radians(shear)), trans_x, np.tan(np.radians(shear)), 1, trans_y)\n",
    "    return pil_img.transform((w, h), Image.AFFINE, matrix, resample=Image.BILINEAR)\n",
    "\n",
    "def augment_image(pil_img):\n",
    "    img = pil_img.copy()\n",
    "    ops = [\n",
    "        lambda x: x.transpose(Image.FLIP_LEFT_RIGHT),\n",
    "        lambda x: x.rotate(random.uniform(-15, 15), resample=Image.BILINEAR),\n",
    "        lambda x: ImageEnhance.Brightness(x).enhance(random.uniform(0.85, 1.15)),\n",
    "        lambda x: ImageEnhance.Contrast(x).enhance(random.uniform(0.85, 1.15)),\n",
    "        lambda x: random_affine(x, max_translate=6, max_shear=3),\n",
    "        lambda x: add_gaussian_noise(x, sigma=random.uniform(5,12)),\n",
    "    ]\n",
    "    for op in random.sample(ops, random.choice([2,3])):\n",
    "        try: img = op(img)\n",
    "        except: pass\n",
    "    return img\n",
    "\n",
    "FINAL_SIZE = (100,100)\n",
    "\n",
    "def generate_until_target(class_folder: Path, target: int):\n",
    "    current_files = list(class_folder.glob(\"*\"))\n",
    "    count = len(current_files)\n",
    "    created, idx = 0, 0\n",
    "    originals = [f for f in current_files if \"_aug\" not in f.name]\n",
    "    pbar = tqdm(total=max(0, target - count), desc=f\"Aug {class_folder.name}\")\n",
    "    while count < target:\n",
    "        src = random.choice(originals)\n",
    "        try:\n",
    "            img = Image.open(src).convert(\"L\")\n",
    "        except: continue\n",
    "        aug = augment_image(img).resize(FINAL_SIZE, Image.BILINEAR)\n",
    "        new_name = f\"{src.stem}_aug{idx:04d}{src.suffix}\"\n",
    "        aug.save(class_folder / new_name)\n",
    "        idx += 1\n",
    "        created += 1\n",
    "        count += 1\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return created\n",
    "\n",
    "created_summary = {}\n",
    "for cls in classes:\n",
    "    cnt = len(list(cls.glob(\"*\")))\n",
    "    if cnt < TARGET:\n",
    "        created_summary[cls.name] = generate_until_target(cls, TARGET)\n",
    "print(\"Imágenes creadas (augmentation):\", created_summary)\n",
    "\n",
    "final_counts = {c.name: len(list(c.glob('*'))) for c in classes}\n",
    "print(\"Conteo final por clase:\", final_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817916fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imágenes balanceadas: 16000\n",
      "label\n",
      "COVID              4000\n",
      "Lung_Opacity       4000\n",
      "Normal             4000\n",
      "Viral Pneumonia    4000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Crear DataFrame actualizado\n",
    "records = []\n",
    "for cls in classes:\n",
    "    for f in cls.glob(\"*\"):\n",
    "        records.append((str(f), cls.name))\n",
    "df = pd.DataFrame(records, columns=[\"image_path\", \"label\"])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "print(\"Total de imágenes balanceadas:\", len(df))\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "# División en conjuntos\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label_encoded\"], random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, stratify=test_df[\"label_encoded\"], random_state=42)\n",
    "\n",
    "# Transformaciones PyTorch\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Dataset personalizado\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx][\"image_path\"]\n",
    "        label = self.data.iloc[idx][\"label_encoded\"]\n",
    "        image = Image.open(img_path).convert(\"L\").resize((100,100))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_loader = DataLoader(ChestXrayDataset(train_df, train_transforms), batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(ChestXrayDataset(val_df, test_transforms), batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(ChestXrayDataset(test_df, test_transforms), batch_size=32, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31ba3b",
   "metadata": {},
   "source": [
    "## PERCEPTRON MULTICAPA MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f76add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando en: cpu\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# MÓDULO 3.1: MLP (Perceptrón Multicapa)\n",
    "# =====================================\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Entrenando en:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd523cc5",
   "metadata": {},
   "source": [
    "### Modelo base con torch \n",
    "Para probar el preprocesamiento \n",
    "\n",
    "recibirá una imagen (1 canal, 100x100 píxeles) → la aplana → pasa por varias capas densas con Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35935d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_Base(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=10000, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP_Base(nn.Module):\n",
    "    def __init__(self, input_size=100*100, num_classes=4, dropout_rate=0.3):\n",
    "        super(MLP_Base, self).__init__()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Crear modelo\n",
    "mlp_model = MLP_Base().to(device)\n",
    "print(mlp_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47081b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001, weight_decay=1e-4)  # regularización L2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c911b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = 100 * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Época [{epoch+1}/{epochs}] - \"\n",
    "              f\"Pérdida entrenamiento: {epoch_loss:.4f} | \"\n",
    "              f\"Pérdida validación: {val_loss:.4f} | \"\n",
    "              f\"Accuracy validación: {val_acc:.2f}%\")\n",
    "    \n",
    "    return train_losses, val_losses, val_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_acc = train_mlp(\n",
    "    mlp_model, train_loader, val_loader, criterion, optimizer, epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43dd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "mlp_model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = mlp_model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "print(\"Reporte de clasificación (Test):\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294bd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label=\"Entrenamiento\")\n",
    "plt.plot(val_losses, label=\"Validación\")\n",
    "plt.title(\"Evolución de la pérdida\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_acc, label=\"Accuracy Validación\")\n",
    "plt.title(\"Evolución del accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
